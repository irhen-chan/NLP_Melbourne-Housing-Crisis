
# Melbourne Housing Crisis â€” NLP & Network Analysis

> Natural-language & network exploration of News articles, Policy documents and Reddit threads on the 2025 Melbourne housing crisis.


## ğŸ“‘ Project at a Glance
| &nbsp; | Highlights |
|-------|------------|
| **Corpus** | 20 public-domain documents across three genres (NEWS 8 ğŸ“°, POLICY 5 ğŸ“œ, REDDIT 7 ğŸ’¬) |
| **Methods** | Â· `tm`, `SnowballC` for preprocessing<br>Â· Harvard GI lexicon for sentiment<br>Â· Cosine-distance clustering (`proxy`, `hclust`)<br>Â· Token/document networks (`igraph`)<br>Â· Bipartite projection & centrality metrics |
| **Findings** | â€¢ **Policy docs** are most optimistic (SentimentGI â†‘)<br>â€¢ **Reddit** acts as a lexical bridge between news & policy<br>â€¢ 26 high-frequency tokens (â€˜housâ€™, â€˜affordâ€™, â€˜homeâ€™, â€¦) dominate all genres |
| **Takeaway** | Despite different voices, every stakeholder repeats the same vocabularyâ€”evidence that new ideas, not new words, are needed to solve the crisis. |


Reflection
â€œEvery dataset tells a story; this one told mine.â€
Building the corpus from scratch (scraping ABC articles, clipping policy PDFs, exporting Reddit threads) taught me that data wrangling is 80 % of analysis. Watching â€œforever-rentersâ€ top every centrality ranking was equal parts validation and frustrationâ€”it mirrored my own struggle to crack Melbourneâ€™s market.

This report earned credit for FIT3152 (2025).
It is published for portfolio purposes only.
Current students must not submit any part of this work as their own; Monash University regards that as plagiarism.
